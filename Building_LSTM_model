import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import LSTM, Dense, Input
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix
import os
import matplotlib.pyplot as plt

# Parameters
learning_rate = 0.0001
training_epochs = 50
batch_size = 16
n_input = 30  # Features per timestep
n_steps = 20  # Timesteps (600 / 30 features per step)
n_hidden = 100  # LSTM units
activities = ["fall", "sitdown", "standup", "walk"]
n_classes = len(activities) + 1  # Output classes (one-hot encoded, +1 for "noactivity")
k_folds = 5

# Output folder
output_folder = f"LR{learning_rate}_BATCHSIZE{batch_size}_NHIDDEN{n_hidden}/"
os.makedirs(output_folder, exist_ok=True)

# Function to load processed data
def load_processed_data():
    x_data_list, y_data_list = [], []

    for label in activities:
        x_file = f"xx_20_60_{label}.csv"
        y_file = f"yy_20_60_{label}.csv"

        x_activity = pd.read_csv(x_file, header=None).values
        y_activity = pd.read_csv(y_file, header=None).values

        x_data_list.append(x_activity)
        y_data_list.append(y_activity)

    # Merge all datasets
    x_data = np.vstack(x_data_list)
    y_data = np.vstack(y_data_list)

    # Reshape x_data to fit LSTM input shape (samples, timesteps, features)
    x_data = x_data.reshape(x_data.shape[0], n_steps, n_input)

    return x_data, y_data

# Define LSTM Model
def create_model():
    inputs = Input(shape=(n_steps, n_input))
    x = LSTM(n_hidden, return_sequences=False)(inputs)
    outputs = Dense(n_classes, activation='softmax')(x)
    model = Model(inputs, outputs)
    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])
    return model

# Load Data
x_data, y_data = load_processed_data()

# K-Fold Cross Validation
kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
cvscores = []
confusion_sum = np.zeros((n_classes, n_classes))

for i, (train_idx, val_idx) in enumerate(kf.split(x_data)):
    print(f"Fold {i+1}/{k_folds}")

    x_train, y_train = x_data[train_idx], y_data[train_idx]
    x_val, y_val = x_data[val_idx], y_data[val_idx]

    model = create_model()
    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=training_epochs, batch_size=batch_size, verbose=1)

    # Evaluate
    scores = model.evaluate(x_val, y_val, verbose=0)
    cvscores.append(scores[1] * 100)

    # Confusion Matrix
    '''y_pred = np.argmax(model.predict(x_val), axis=1)
    y_true = np.argmax(y_val, axis=1)
    confusion = confusion_matrix(y_true, y_pred)
    confusion_sum += confusion'''

    # Save Accuracy and Loss Graphs
    plt.figure()
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend(["Train", "Validation"], loc="lower right")
    plt.savefig(f"{output_folder}Accuracy_Fold_{i}.png")

    plt.figure()
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(["Train", "Validation"], loc="upper right")
    plt.savefig(f"{output_folder}Loss_Fold_{i}.png")

# Save final results
#np.savetxt(f"{output_folder}confusion_matrix.txt", confusion_sum, delimiter=",", fmt='%d')
np.savetxt(f"{output_folder}accuracy.txt", [np.mean(cvscores), np.std(cvscores)], delimiter=",", fmt='%.1f')
print(f"Final Accuracy: {np.mean(cvscores):.1f}% (+/- {np.std(cvscores):.1f}%)")
